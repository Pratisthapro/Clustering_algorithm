{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":74935,"sourceType":"datasetVersion","datasetId":42674}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Clustering Steps:\n1. Importing Libraries\n2. Exploration of data\n3. Data Visualization\n4. Clustering using K-Means\n5. Selection of Clusters\n6. Ploting the Cluster Boundry and Clusters\n7. 3D Plot of Clusters\n8. Custering using K proto","metadata":{"_uuid":"054f0cca3061be223d76116cb8544b598eb5a297"}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{"_uuid":"fd0fc89fe26333add074845d0629b52ae828584c"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport plotly as py\nimport plotly.graph_objs as go\nfrom sklearn.cluster import KMeans\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-10-05T12:47:45.627884Z","iopub.execute_input":"2024-10-05T12:47:45.628349Z","iopub.status.idle":"2024-10-05T12:47:45.636677Z","shell.execute_reply.started":"2024-10-05T12:47:45.628307Z","shell.execute_reply":"2024-10-05T12:47:45.635169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{"_uuid":"5b838f778af8cb2740c6d54e5bb6608223ab54f4"}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\ndf = df.drop('CustomerID', axis=1)\ndf.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2024-10-05T13:07:51.844574Z","iopub.execute_input":"2024-10-05T13:07:51.845033Z","iopub.status.idle":"2024-10-05T13:07:51.861520Z","shell.execute_reply.started":"2024-10-05T13:07:51.844982Z","shell.execute_reply":"2024-10-05T13:07:51.860332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"_uuid":"0e352ff53fe883942afd06b2e830ff7fa7cfdabd","execution":{"iopub.status.busy":"2024-10-05T13:07:53.729749Z","iopub.execute_input":"2024-10-05T13:07:53.730232Z","iopub.status.idle":"2024-10-05T13:07:53.755151Z","shell.execute_reply.started":"2024-10-05T13:07:53.730186Z","shell.execute_reply":"2024-10-05T13:07:53.753774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"_uuid":"57e39b6ed035b3e1b9e3dda9efd273fe552f48a7","execution":{"iopub.status.busy":"2024-10-05T13:07:54.594856Z","iopub.execute_input":"2024-10-05T13:07:54.595315Z","iopub.status.idle":"2024-10-05T13:07:54.607384Z","shell.execute_reply.started":"2024-10-05T13:07:54.595271Z","shell.execute_reply":"2024-10-05T13:07:54.605916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"_uuid":"e57f14ca0de9ce6d08a1dd1fb6470707db3eb85a","execution":{"iopub.status.busy":"2024-10-05T13:07:54.609728Z","iopub.execute_input":"2024-10-05T13:07:54.610229Z","iopub.status.idle":"2024-10-05T13:07:54.624908Z","shell.execute_reply.started":"2024-10-05T13:07:54.610185Z","shell.execute_reply":"2024-10-05T13:07:54.623760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{"_uuid":"2459a03e13d3bae3d946715b17c151f0615b3dcf"}},{"cell_type":"markdown","source":"### Histograms","metadata":{"_uuid":"0ee494fa3103f3aead92791fd958ac8e97b7beed"}},{"cell_type":"code","source":"plt.figure(figsize = (15 , 6))\nn = 0 \nfor x in ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']:\n    n += 1\n    plt.subplot(1 , 3 , n)\n    sns.distplot(df[x] , bins = 20)\n    plt.title('Distplot of {}'.format(x))\nplt.tight_layout()","metadata":{"_kg_hide-input":true,"_uuid":"7e72632388acada5fd66e2323f0544af06cac54d","execution":{"iopub.status.busy":"2024-10-05T13:07:55.290008Z","iopub.execute_input":"2024-10-05T13:07:55.290455Z","iopub.status.idle":"2024-10-05T13:07:56.467966Z","shell.execute_reply.started":"2024-10-05T13:07:55.290412Z","shell.execute_reply":"2024-10-05T13:07:56.466526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### \n- data has mix of distributions (Age is slightly skewed, Annual Income is somewhat normal but has outliers, Spending Score is more uniform), scaling the features becomes crucial.\n- we will use standardization (z-score normalization) or min-max scaling to ensure each feature contributes equally to the clustering algorithm, especially for K-Means and K-Prototypes","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nn = 0\n\n# Loop through the columns for Age, Annual Income, and Spending Score\nfor cols in ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']:\n    n += 1\n    plt.subplot(1, 3, n)\n    plt.subplots_adjust(hspace=0.5, wspace=0.5)\n    \n    # Boxplot for each column with respect to Gender\n    sns.boxplot(x=cols, y='Gender', data=df, palette='vlag')\n    \n    # Conditional labels and title\n    plt.ylabel('Gender' if n == 1 else '')\n    plt.title('Boxplots & Swarmplots' if n == 2 else '')","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:08:03.072750Z","iopub.execute_input":"2024-10-05T13:08:03.073157Z","iopub.status.idle":"2024-10-05T13:08:03.574502Z","shell.execute_reply.started":"2024-10-05T13:08:03.073110Z","shell.execute_reply":"2024-10-05T13:08:03.573345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count Plot of Gender","metadata":{"_uuid":"f3b491e34170ac1ee8e670bf1292fb8e451d5053"}},{"cell_type":"code","source":"plt.figure(figsize = (15 , 5))\nsns.countplot(y = 'Gender' , data = df)","metadata":{"_kg_hide-input":true,"_uuid":"befa7a57e4e37f96c8644b24e6982f354e964864","execution":{"iopub.status.busy":"2024-10-05T13:07:56.470100Z","iopub.execute_input":"2024-10-05T13:07:56.470617Z","iopub.status.idle":"2024-10-05T13:07:56.729012Z","shell.execute_reply.started":"2024-10-05T13:07:56.470559Z","shell.execute_reply":"2024-10-05T13:07:56.727845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ploting the Relation between Age , Annual Income and Spending Score","metadata":{"_uuid":"fcc79189184015bc626be9264fbd2836b2ebad8c"}},{"cell_type":"code","source":"plt.figure(1 , figsize = (15 , 7))\nn = 0 \nfor x in ['Age' , 'Annual Income (k$)' , 'Spending Score (1-100)']:\n    for y in ['Age' , 'Annual Income (k$)' , 'Spending Score (1-100)']:\n        n += 1\n        plt.subplot(3 , 3 , n)\n        plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n        sns.regplot(x = x , y = y , data = df)\n        plt.ylabel(y.split()[0]+' '+y.split()[1] if len(y.split()) > 1 else y )","metadata":{"_kg_hide-input":true,"_uuid":"89e99c64c4e69e1141090185da444c8991e5ce8f","execution":{"iopub.status.busy":"2024-10-05T13:07:56.974658Z","iopub.execute_input":"2024-10-05T13:07:56.975566Z","iopub.status.idle":"2024-10-05T13:07:59.566355Z","shell.execute_reply.started":"2024-10-05T13:07:56.975518Z","shell.execute_reply":"2024-10-05T13:07:59.564847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n- Age vs. Annual Income: no clear relationship (random spread of points).Clustering these two may not reveal strong natural clusters.\n\n- Age vs. Spending Score: slight negative correlation. Younger customers tend to have higher Spending Scores, while older customers tend to have lower Spending Scores.This relationship could be useful for clustering, especially if you want to segment customers based on spending habits and age groups.\n\n- Annual Income vs. Spending Score: two major groupings of Spending Scores: One near low Spending Scores (0-40). Another near high Spending Scores (60-100)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15 , 6))\nfor gender in ['Male' , 'Female']:\n    plt.scatter(x = 'Age' , y = 'Annual Income (k$)' , data = df[df['Gender'] == gender] ,\n                s = 200 , alpha = 0.5 , label = gender)\nplt.xlabel('Age'), plt.ylabel('Annual Income (k$)') \nplt.title('Age vs Annual Income w.r.t Gender')\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"_uuid":"18679353d562a05276b4ece94738f06b6b1e7d5b","execution":{"iopub.status.busy":"2024-10-05T13:07:59.569655Z","iopub.execute_input":"2024-10-05T13:07:59.570240Z","iopub.status.idle":"2024-10-05T13:08:00.002343Z","shell.execute_reply.started":"2024-10-05T13:07:59.570183Z","shell.execute_reply":"2024-10-05T13:08:00.000871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15 , 6))\nfor gender in ['Male' , 'Female']:\n    plt.scatter(x = 'Annual Income (k$)',y = 'Spending Score (1-100)' ,\n                data = df[df['Gender'] == gender] ,s = 200 , alpha = 0.5 , label = gender)\nplt.xlabel('Annual Income (k$)'), plt.ylabel('Spending Score (1-100)') \nplt.title('Annual Income vs Spending Score w.r.t Gender')\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"_uuid":"0cc3399fa8aebfa774c7ba298ee998e323c6c86b","execution":{"iopub.status.busy":"2024-10-05T13:08:00.004002Z","iopub.execute_input":"2024-10-05T13:08:00.004469Z","iopub.status.idle":"2024-10-05T13:08:00.432212Z","shell.execute_reply.started":"2024-10-05T13:08:00.004418Z","shell.execute_reply":"2024-10-05T13:08:00.430877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of values in Age , Annual Income and Spending Score according to Gender","metadata":{"_uuid":"9f55e102bd9a6ec847ec61fa67479f21cafa7fde"}},{"cell_type":"code","source":"plt.figure(figsize = (15 , 7))\nn = 0 \nfor cols in ['Age' , 'Annual Income (k$)' , 'Spending Score (1-100)']:\n    n += 1 \n    plt.subplot(1 , 3 , n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n    sns.violinplot(x = cols , y = 'Gender' , data = df , palette = 'vlag')\n    sns.swarmplot(x = cols , y = 'Gender' , data = df)\n    plt.ylabel('Gender' if n == 1 else '')\n    plt.title('Boxplots & Swarmplots' if n == 2 else '')\nplt.show()","metadata":{"_kg_hide-input":true,"_uuid":"c0b99c70642918f21368920c3d3fb42207539eae","execution":{"iopub.status.busy":"2024-10-05T13:08:00.800790Z","iopub.execute_input":"2024-10-05T13:08:00.801353Z","iopub.status.idle":"2024-10-05T13:08:03.070999Z","shell.execute_reply.started":"2024-10-05T13:08:00.801300Z","shell.execute_reply":"2024-10-05T13:08:03.069765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### this boxplot shows that data doesn't have many outliers","metadata":{}},{"cell_type":"markdown","source":"# Scaling data for distance based algorithms","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:08:03.576080Z","iopub.execute_input":"2024-10-05T13:08:03.576498Z","iopub.status.idle":"2024-10-05T13:08:03.582153Z","shell.execute_reply.started":"2024-10-05T13:08:03.576457Z","shell.execute_reply":"2024-10-05T13:08:03.580844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(features)\nscaled_df = pd.DataFrame(scaled_features, columns=['Age', 'Annual Income (k$)', 'Spending Score (1-100)'])\nprint(scaled_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:08:03.583747Z","iopub.execute_input":"2024-10-05T13:08:03.584157Z","iopub.status.idle":"2024-10-05T13:08:03.605443Z","shell.execute_reply.started":"2024-10-05T13:08:03.584109Z","shell.execute_reply":"2024-10-05T13:08:03.603781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clustering using K- means","metadata":{"_uuid":"ab264c94de58ad05158ad3bfd95a9fd35f4106de"}},{"cell_type":"markdown","source":"## Finding best K ","metadata":{}},{"cell_type":"code","source":"# Step 1: Convert Gender to numerical values\ndf['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n\n# Define the feature pairs to evaluate\nfeature_pairs = [\n    ['Age', 'Annual Income (k$)'],\n    ['Age', 'Spending Score (1-100)'],\n    ['Annual Income (k$)', 'Spending Score (1-100)']\n]\n\n# Step 2: Determine optimal K using Elbow Method\nfor features in feature_pairs:\n    X = df[features]\n    \n    inertia = []\n    K_range = range(1, 11)  # Testing K from 1 to 10\n    for k in K_range:\n        kmeans = KMeans(n_clusters=k, random_state=42)\n        kmeans.fit(X)\n        inertia.append(kmeans.inertia_)\n    \n    # Plot the Elbow Method\n    plt.figure(figsize=(8, 5))\n    plt.plot(K_range, inertia, marker='o')\n    plt.title(f'Elbow Method for {features[0]} and {features[1]}')\n    plt.xlabel('Number of Clusters (K)')\n    plt.ylabel('Inertia')\n    plt.xticks(K_range)\n    plt.grid()","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:13:58.790549Z","iopub.execute_input":"2024-10-05T13:13:58.791112Z","iopub.status.idle":"2024-10-05T13:14:00.395277Z","shell.execute_reply.started":"2024-10-05T13:13:58.791032Z","shell.execute_reply":"2024-10-05T13:14:00.394113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K means model for k=3","metadata":{}},{"cell_type":"code","source":"# Assuming the best K was determined to be 3 for demonstration purposes\nbest_k = 3\n\n# Step 3: Apply K-Means with the best K for each feature pair\nfor features in feature_pairs:\n    X = df[features]\n    kmeans = KMeans(n_clusters=best_k, random_state=42)\n    df[f'Cluster_{features[0]}_{features[1]}'] = kmeans.fit_predict(X)\n    \n    # Visualize the clusters\n    plt.figure(figsize=(8, 6))\n    sns.scatterplot(data=df, x=features[0], y=features[1], hue=f'Cluster_{features[0]}_{features[1]}', palette='viridis')\n    plt.title(f'K-Means Clustering with {best_k} Clusters for {features[0]} and {features[1]}')\n    plt.xlabel(features[0])\n    plt.ylabel(features[1])\n    plt.legend(title='Cluster')","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:30.175641Z","iopub.execute_input":"2024-10-05T13:15:30.176171Z","iopub.status.idle":"2024-10-05T13:15:31.752506Z","shell.execute_reply.started":"2024-10-05T13:15:30.176114Z","shell.execute_reply":"2024-10-05T13:15:31.751087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K means model for k=5","metadata":{}},{"cell_type":"code","source":"# Assuming the best K was determined to be 3 for demonstration purposes\nbest_k = 5\n\n# Step 3: Apply K-Means with the best K for each feature pair\nfor features in feature_pairs:\n    X = df[features]\n    kmeans = KMeans(n_clusters=best_k, random_state=42)\n    df[f'Cluster_{features[0]}_{features[1]}'] = kmeans.fit_predict(X)\n    \n    # Visualize the clusters\n    plt.figure(figsize=(8, 6))\n    sns.scatterplot(data=df, x=features[0], y=features[1], hue=f'Cluster_{features[0]}_{features[1]}', palette='viridis')\n    plt.title(f'K-Means Clustering with {best_k} Clusters for {features[0]} and {features[1]}')\n    plt.xlabel(features[0])\n    plt.ylabel(features[1])\n    plt.legend(title='Cluster')","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:19:57.445104Z","iopub.execute_input":"2024-10-05T13:19:57.445767Z","iopub.status.idle":"2024-10-05T13:20:00.107882Z","shell.execute_reply.started":"2024-10-05T13:19:57.445690Z","shell.execute_reply":"2024-10-05T13:20:00.106580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Annual Income vs Spending Score (1-100)\n- Label 2 is low income and low spending\n- Label 3 is low income and high spending\n- Label 1 is high income and low spending\n- Label 0 is mid income and mid spending\n- Label 4 is high income and high spending","metadata":{}},{"cell_type":"markdown","source":"# Clustering using K Proto","metadata":{}},{"cell_type":"code","source":"!pip install kmodes\nfrom kmodes.kprototypes import KPrototypes","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:47:56.684203Z","iopub.execute_input":"2024-10-05T12:47:56.684682Z","iopub.status.idle":"2024-10-05T12:48:10.752305Z","shell.execute_reply.started":"2024-10-05T12:47:56.684628Z","shell.execute_reply":"2024-10-05T12:48:10.750644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scaled_df contains scaled numerical columns and df contains original data with categorical columns\n\n# Extract categorical column(s) from original df\ndf_cat = df['Gender']\n\n# Combine scaled numerical columns with categorical column(s)\n# scaled_df should have the same index as df_cat\nfinal_df = pd.concat([scaled_df.reset_index(drop=True), df_cat.reset_index(drop=True)], axis=1)\n\n# Display the new dataframe prepared for K-Prototypes modeling\nprint(final_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:48:10.754737Z","iopub.execute_input":"2024-10-05T12:48:10.755302Z","iopub.status.idle":"2024-10-05T12:48:10.772162Z","shell.execute_reply.started":"2024-10-05T12:48:10.755241Z","shell.execute_reply":"2024-10-05T12:48:10.770783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding Optimum Cluster (k) Using Elbow Method","metadata":{}},{"cell_type":"code","source":"costs = []\nK_range = range(1, 10)  # Checking for k values from 1 to 10\n\nfor k in K_range:\n    kproto = KPrototypes(n_clusters=k, init='Huang', random_state=42)\n    kproto.fit_predict(final_df, categorical=[3])  # Assuming 'Gender' is categorical\n    costs.append(kproto.cost_)\n\n# Plotting the elbow curve\nplt.plot(K_range, costs, 'bo-')\nplt.xlabel('Number of clusters (k)')\nplt.ylabel('Cost')\nplt.title('Elbow Method for Optimal k')","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:48:10.773881Z","iopub.execute_input":"2024-10-05T12:48:10.774286Z","iopub.status.idle":"2024-10-05T12:48:26.622280Z","shell.execute_reply.started":"2024-10-05T12:48:10.774220Z","shell.execute_reply":"2024-10-05T12:48:26.620651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding Optimum Cluster (k) Using Silhoutte Score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import silhouette_score\n\n# Convert categorical columns to numerics for silhouette calculation (since it's for numerical data only)\ndf_for_silhouette = final_df.copy()\ndf_for_silhouette['Gender'] = df_for_silhouette['Gender'].map({'Male': 0, 'Female': 1})\nprint(df_for_silhouette)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:48:26.623580Z","iopub.execute_input":"2024-10-05T12:48:26.623982Z","iopub.status.idle":"2024-10-05T12:48:26.636634Z","shell.execute_reply.started":"2024-10-05T12:48:26.623938Z","shell.execute_reply":"2024-10-05T12:48:26.635476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"silhouette_scores = []\nK_range = range(2, 10)  # Silhouette score requires at least 2 clusters\n\nfor k in K_range:\n    kproto = KPrototypes(n_clusters=k, init='Huang', random_state=42)\n    clusters = kproto.fit_predict(df_for_silhouette, categorical=[3])\n    \n    # Compute silhouette score (using the numerical features only)\n    score = silhouette_score(df_for_silhouette, clusters)\n    silhouette_scores.append(score)\n\n# Plotting the silhouette score curve\nplt.plot(K_range, silhouette_scores, 'bo-')\nplt.xlabel('Number of clusters (k)')\nplt.ylabel('Silhouette Score')\nplt.title('Silhouette Score for Optimal k')","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:48:26.638138Z","iopub.execute_input":"2024-10-05T12:48:26.638534Z","iopub.status.idle":"2024-10-05T12:48:42.174309Z","shell.execute_reply.started":"2024-10-05T12:48:26.638494Z","shell.execute_reply":"2024-10-05T12:48:42.173091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# K-Prototypes model\nkproto = KPrototypes(n_clusters=3, init='Huang', random_state=42)\n\n# Fitting the model (the index 0 corresponds to the categorical column 'Gender')\nclusters = kproto.fit_predict(final_df, categorical=[3])\n\n# Assign the cluster labels back to the dataframe\nfinal_df['Cluster'] = clusters\n\n# Output the clustered data\nprint(final_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:48:42.176290Z","iopub.execute_input":"2024-10-05T12:48:42.176664Z","iopub.status.idle":"2024-10-05T12:48:43.664970Z","shell.execute_reply.started":"2024-10-05T12:48:42.176624Z","shell.execute_reply":"2024-10-05T12:48:43.663631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Checking Cluster Distribution Across All Features","metadata":{}},{"cell_type":"markdown","source":"#### K-Prototypes algorithm clusters based on all columns, not just Annual Income and Spending Score. However, in visualization, we are only plotting those two variables because it's easier to plot 2D or 3D data.","metadata":{}},{"cell_type":"code","source":"# Scatter plot of clusters based on 'Annual Income' and 'Spending Score'\nplt.scatter(final_df['Annual Income (k$)'], final_df['Spending Score (1-100)'], c=final_df['Cluster'])\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.title('K-Prototypes Clusters based on Annual Income and Spending Score')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:48:43.666356Z","iopub.execute_input":"2024-10-05T12:48:43.666798Z","iopub.status.idle":"2024-10-05T12:48:43.999105Z","shell.execute_reply.started":"2024-10-05T12:48:43.666748Z","shell.execute_reply":"2024-10-05T12:48:43.997781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Using pairplot to visualize how clusters vary across all pairs of numerical features","metadata":{}},{"cell_type":"code","source":"# Convert the cluster labels to categorical (if not already) for proper coloring in pairplot\nfinal_df['Cluster'] = final_df['Cluster'].astype(str)\n\n# Select numerical columns for pairplot\nnum_cols = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n\n# Generate pairplot\nsns.pairplot(final_df[num_cols + ['Cluster']], hue='Cluster', palette='Set1', diag_kind='kde', plot_kws={'alpha':0.6, 's':80})","metadata":{"execution":{"iopub.status.busy":"2024-10-05T12:48:44.000829Z","iopub.execute_input":"2024-10-05T12:48:44.001344Z","iopub.status.idle":"2024-10-05T12:48:48.294102Z","shell.execute_reply.started":"2024-10-05T12:48:44.001287Z","shell.execute_reply":"2024-10-05T12:48:48.292772Z"},"trusted":true},"execution_count":null,"outputs":[]}]}